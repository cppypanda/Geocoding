### 置信度算法规格书 (SOP)

**版本: 1.0**  
**最后更新日期: 2025-08-26**

---

#### 1. 概述

本文档定义了地理编码系统中使用的统一置信度计算算法。该算法用于评估地址匹配的准确性，支持多种应用场景，包括多源地理编码和POI搜索功能。

##### 1.1. 适用范围

为确保对不同数据源进行最有效的评估，本算法的适用范围明确如下：

*   **兴趣点搜索 (POI) 场景**: **适用于所有数据源** (高德、百度、天地图)。由于各POI搜索服务均不提供原生的匹配度分数，因此所有返回的POI结果都必须通过本算法进行统一的置信度评估。

*   **地理编码 (Geocoding) 场景**: **仅适用于高德地图**。
    *   **原因**: 高德地理编码返回详细的候选地址文本，但**不提供**原生置信度分数，因此必须使用本算法进行计算。
    *   **例外**: 百度地图和天地图的地理编码服务会返回其**原生置信度分数**，但**不提供**可供比较的详细地址文本。因此，对于这两个数据源，系统应直接采纳并标准化其原生分数，而**不使用**本算法。

#### 2. 核心设计原则

*   **统一性**: 提供统一的置信度计算接口，支持不同的应用模式
*   **灵活性**: 根据不同场景采用不同的匹配策略
*   **可扩展性**: 支持新的匹配算法和评估维度
*   **可解释性**: 提供详细的计算过程日志，便于调试和优化

---

#### 3. 算法架构

##### 3.1. 核心输入

置信度计算流程需要以下三项核心数据作为输入：

1.  **原始查询**: 用户输入的、未经任何处理的原始地址或关键词字符串。
2.  **结构化查询**: 经过系统上游地址解析服务处理后的结构化数据。该数据包含了原始查询的省级、市级、区县级行政区划以及核心地址详情。这是算法进行精确匹配和过滤的主要依据。
3.  **候选数据**: 从外部数据源（如地图API、POI数据库）获取的，需要被评估的单条候选结果。

##### 3.2. 计算模式

为了适应不同的业务场景，算法支持两种计算模式，系统会根据调用场景自动选择：

*   **地理编码模式 (`geocoding`)**: 此模式专门用于评估标准地址的匹配度。它适用于多源地理编码服务中，对各个地图供应商返回的地址结果进行统一的置信度打分。
*   **兴趣点搜索模式 (`poi`)**: 此模式用于评估兴趣点（POI）的匹配度。它适用于POI搜索功能，评估返回的商户、地点等结果与用户查询的匹配程度。

##### 3.3. 算法流程

```
输入验证 → 地址解析 → 行政区划过滤 → 模式分发 → 置信度计算 → 结果返回
```

---

#### 4. 行政区划硬性过滤

作为置信度计算的第一步，所有候选数据都必须通过与“结构化查询”的行政区划匹配检查。任何一项检查失败，置信度将直接计为 `0.0`，计算流程提前终止。

*   **数据源**:
    *   **查询方**: 使用“结构化查询”中的 `province`, `city`, `county` 字段。
    *   **候选方**: 根据数据源类型，使用对应的行政区划字段（例如，地理编码结果的 `province`, `city`, `district` 或 POI 结果的 `pname`, `cityname`, `adname`）。

*   **匹配规则**:
    1.  **省级匹配**: 双方的省级信息必须完全一致。
    2.  **市级匹配**: 双方的市级信息必须完全一致。
    3.  **区县级条件匹配**: 当且仅当用户的“结构化查询”中明确包含区县信息时，才进行此项检查。若检查，则双方区县信息必须完全一致。

---

#### 5. 统一置信度计算模型

通过行政区划过滤后，算法采用统一的多维度匹配模型计算最终置信度。其核心思想是通过交叉对比“查询源”与“候选维度”的文本相似度，并选取最高分作为结果，以实现最佳的匹配效果和容错性。

##### 5.1. 核心文本预处理

在进行相似度计算之前，所有用于比较的文本（无论来自查询方还是候选方）都必须经过两个标准化的预处理步骤，以消除格式差异、提纯核心内容。

1.  **地址后缀移除**: 移除文本末尾在册的、无实际意义的通用后缀（如“交叉口”、“收费站”等），以提取地址的核心关键词。
2.  **文本标准化**: 进行全角转半角、统一转为小写、移除所有空白字符等操作，确保比较不受格式影响。

##### 5.2. 定义比较源与候选维度

预处理之后，算法从输入数据中定义出用于交叉对比的“比较源”（来自用户）和“候选维度”（来自候选数据）。

*   **比较源 (Query Sources)**
    1.  **查询详情 (Source-Detail)**: 从“结构化查询”中获取的核心地址详情 (`detail`)。这是最精准的比较源。
    2.  **查询全文 (Source-Full)**: 用户输入的原始字符串。它包含最完整的信息，作为对解析结果的补充和容错。

*   **候选维度 (Candidate Dimensions)**
    *   **主要维度 (Primary Dimensions - 用于核心匹配)**
        1.  **候选名称详情 (Dim-Name-Detail)**: 对候选数据的名称字段 (如 POI 的 `name`) 进行地址解析后，提取出的核心详情。
        2.  **候选地址详情 (Dim-Address-Detail)**: 对候选数据的地址字段 (如 `formatted_address`) 进行地址解析后，提取出的核心详情。
    *   **补充维度 (Supplementary Dimensions - 用于容错匹配)**
        1.  **候选名称全文 (Dim-Name-Full)**: 候选数据未经解析的、完整的名称字段。
        2.  **候选地址全文 (Dim-Address-Full)**: 候选数据未经解析的、完整的地址字段。

##### 5.3. 计算策略

算法根据不同的计算模式，采用不同的策略组合“比较源”和“候选维度”进行计算。

*   **兴趣点搜索模式 (`poi`) — 融合策略**

   此模式采用“主路径优先，补充路径容错”的融合策略，以达到精度和召回率的平衡。
   
   1.  **主路径计算 (核心详情匹配)**: 优先进行最精准的“详情 vs 详情”匹配。
       *   `查询详情` vs `候选名称详情`
       *   `查询详情` vs `候选地址详情`
   
   2.  **补充路径计算 (全文容错匹配)**: 进行“全文 vs 全文”匹配，以兼容解析不佳或别名的情况。
       *   `查询全文` vs `候选名称全文`
       *   `查询全文` vs `候选地址全文`

   **最终置信度**: 取以上主、补充两条路径所有计算结果中的 **最高分**。

*   **地理编码模式 (`geocoding`) — 简化策略**

   此模式的目标是评估两个标准地址的匹配度，因此采用最直接的简化策略，只进行 **1组** 核心比较：
    1.  `查询详情` vs `候选地址详情` (需对候选地址进行解析)

   **最终置信度**: 即为该组的计算结果。这本质上是“融合策略”在只关心地址详情匹配下的一个特例。

---

#### 6. 相似度评分：包含关系增强算法

所有“比较源”与“候选维度”的文本相似度计算，均采用统一的“包含关系增强算法”。该算法基于标准的编辑距离（Levenshtein），并对文本间的包含关系进行特殊加权，以更精准地反映真实匹配度。

##### 6.1. 算法目标
*   识别文本间的包含关系（如 “北京饭店” 包含在 “北京饭店(西门)” 中）。
*   根据包含关系的方向、文本长度和占比，给予差异化的、更符合用户直觉的分数。
*   避免泛化的短词（如“饭店”）因包含在长文本中而获得不成比例的高分。

##### 6.2. 评分细则

**情况A: 查询文本 包含于 候选文本**
*   **语义**: 用户搜索一个相对宽泛的词，而候选结果是一个更具体的地点。例如，用户搜 `星巴克`，候选是 `星巴克(万达广场店)`。
*   **评分策略**: 匹配度非常高。给予 **80% - 100%** 的高额基础分，并根据文本长度重合比例微调。

**情况B: 候选文本 包含于 查询文本**
*   **语义**: 候选结果的名称是用户搜索词的一部分。例如，用户搜 `王府井大街的工商银行`，候选是 `工商银行`。
*   **评分策略**: 匹配度较高，但需更谨慎。基于候选文本的“特异性”（长度和在查询文本中的占比）给予 **50% - 95%** 的浮动分数，避免因匹配到通用词而导致误判。

##### 6.3. 示例代码 (逻辑示意)

**情况A: 原始地址包含在候选地址中**
```python
if original_detail in candidate_detail:
    contain_ratio = len(original_detail) / len(candidate_detail)
    if contain_ratio >= 0.8:
        confidence = max(base_similarity, 0.95 + contain_ratio * 0.05)  # 95%-100%
    elif contain_ratio >= 0.5:
        confidence = max(base_similarity, 0.90 + contain_ratio * 0.10)  # 90%-95%
    else:
        confidence = max(base_similarity, 0.80 + contain_ratio * 0.20)  # 80%-90%
```

**情况B: 候选地址包含在原始地址中**
```python
if candidate_detail in original_detail:
    contain_ratio = len(candidate_detail) / len(original_detail)
    candidate_length = len(candidate_detail)
    
    if candidate_length >= 4 and contain_ratio >= 0.3:
        confidence = max(base_similarity, 0.75 + contain_ratio * 0.20)  # 75%-95%
    elif candidate_length >= 3 and contain_ratio >= 0.2:
        confidence = max(base_similarity, 0.65 + contain_ratio * 0.20)  # 65%-85%
    else:
        confidence = max(base_similarity, 0.50 + contain_ratio * 0.25)  # 50%-75%
```

---

#### 7. 工具函数说明

##### 7.1. 地址后缀移除
```python
def remove_suffixes(address: str) -> str
```
*   **数据源**: `location_types` 数据库表中 `status='approved'` 的后缀
*   **处理逻辑**: 按长度降序移除，确保最长匹配优先
*   **目的**: 提取地址核心部分，提升匹配精度

##### 7.2. 文本标准化
```python
def _normalize_detail_for_confidence(text: str) -> str
```
*   **处理内容**: 去除空格、统一大小写、特殊字符处理
*   **目的**: 消除格式差异对相似度计算的影响

##### 7.3. 包含关系计算
```python
def _calculate_text_similarity_with_containment(text1: str, text2: str, dimension_name: str) -> float
```
*   **基础计算**: `Levenshtein.ratio` 编辑距离相似度
*   **增强处理**: 包含关系检测和评分提升
*   **日志记录**: 详细的计算过程和结果

---

#### 8. 性能优化

##### 8.1. 计算复杂度
*   行政区划过滤: O(1)
*   文本相似度计算: O(n*m)，其中n、m为文本长度
*   多维度评估: 线性复杂度，与维度数量成正比

##### 8.2. 缓存策略
*   地址解析结果缓存
*   后缀移除结果缓存
*   标准化文本缓存

##### 8.3. 早期退出
*   行政区划不匹配时立即返回0.0
*   单维度模式下无需计算其他维度

---

#### 9. 测试与验证

##### 9.1. 基准测试用例
*   完全匹配: 置信度应接近1.0
*   包含关系: 根据包含类型给予合理分数
*   无关地址: 置信度应接近0.0
*   边缘情况: 空字符串、特殊字符等

##### 9.2. 回归测试
*   算法更新后必须通过所有基准测试
*   对比新旧算法结果，确保改进有效
*   监控实际使用中的置信度分布

---

#### 10. 日志与调试

##### 10.1. 日志级别
*   **DEBUG**: 详细的计算过程和中间结果
*   **INFO**: 最终置信度和选择的维度
*   **WARNING**: 异常情况和降级处理

##### 10.2. 关键日志内容
*   行政区划匹配结果
*   各维度置信度计算过程
*   包含关系检测结果
*   最终选择的维度和置信度

---

**文档版本说明**: 本算法文档将随着系统优化持续更新，所有算法变更都应同步更新此文档。
